{"version":3,"sources":["../../../../nodes/llms/LMChatOpenAi/types.ts"],"sourcesContent":["import type { OpenAIClient } from '@langchain/openai';\n\nexport type BuiltInTools = {\n\twebSearch?: {\n\t\tsearchContextSize?: 'low' | 'medium' | 'high';\n\t\tallowedDomains?: string;\n\t\tcountry?: string;\n\t\tcity?: string;\n\t\tregion?: string;\n\t};\n\tfileSearch?: {\n\t\tvectorStoreIds?: string;\n\t\tfilters?: string;\n\t\tmaxResults?: number;\n\t};\n\tcodeInterpreter?: boolean;\n};\n\nexport type ModelOptions = {\n\tbaseURL?: string;\n\tfrequencyPenalty?: number;\n\tmaxTokens?: number;\n\tresponseFormat?: 'text' | 'json_object';\n\tpresencePenalty?: number;\n\ttemperature?: number;\n\treasoningEffort?: 'low' | 'medium' | 'high';\n\ttimeout?: number;\n\tmaxRetries?: number;\n\ttopP?: number;\n\tconversationId?: string;\n\tmetadata?: string;\n\tpromptCacheKey?: string;\n\tsafetyIdentifier?: string;\n\tserviceTier?: 'auto' | 'flex' | 'default' | 'priority';\n\ttopLogprobs?: number;\n\ttextFormat?: {\n\t\ttextOptions?: TextOptions;\n\t};\n\tpromptConfig?: {\n\t\tpromptOptions?: PromptOptions;\n\t};\n};\n\nexport type PromptOptions = {\n\tpromptId?: string;\n\tversion?: string;\n\tvariables?: string;\n};\n\nexport type TextOptions = {\n\ttype?: 'text' | 'json_schema' | 'json_object';\n\tverbosity?: 'low' | 'medium' | 'high';\n\tname?: string;\n\tschema?: string;\n\tdescription?: string;\n\tstrict?: boolean;\n};\nexport type ChatResponseRequest = OpenAIClient.Responses.ResponseCreateParamsNonStreaming & {\n\tconversation?: { id: string } | string;\n\ttop_logprobs?: number;\n};\n"],"mappings":";;;;;;;;;;;;;;AAAA;AAAA;","names":[]}